{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37abd0c1-f3bc-4c91-80b2-3b14f385ef97",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "# Perceptron, SVM, and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41a524-ade8-4277-bffc-7547379f9d22",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: right;\"> &#9989; Ronnit Chopra </p>\n",
    "# <p style=\"text-align: right;\"> &#9989; KlutzyFella </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e13b3-c564-4b25-9e3f-8bef7e3cd6e3",
   "metadata": {},
   "source": [
    "# Goal for this homework assignment\n",
    "We have worked some basics on perceptron, SVM, and PCA in the pre-class and in-class assignments. In this homework assignment, we will:\n",
    "\n",
    "* Continue to use git as the version control tool\n",
    "* Work on unfamiliar data\n",
    "* Use perceptron to classify data \n",
    "* Use SVM to classify data\n",
    "* Use principal component analysis to facilitate classification\n",
    "\n",
    "\n",
    "**This assignment is due by 11:59 pm on Friday, April 25th. Note that ONLY the copy on GITHUB will be graded.**  **There are 60 standard points possible in this assignment including points for Git commits/pushes. The distribution of points can be found in the section headers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199515ba-e709-40e2-a189-5da69a6f1699",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Git repository (6 points)\n",
    "\n",
    "You're going to add this assignment to the `cmse202-s25-turnin` repository you previously created. The history of progress on the assignment will be tracked via git commitments. \n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s25-turnin` **local** repository and create a new directory called `hw-04`\n",
    "\n",
    "2. Move this notebook into that **new directory** in your repository. \n",
    "\n",
    "5. Double check to make sure your file is at the correct directory.\n",
    "\n",
    "6. Once you're certain that file and directory are correct, add this notebook to your repository, then make a commit and push it to GitHub. You may need to use `git push origin hw04` to push your file to GitHub.\n",
    "\n",
    "Finally, &#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below. **Points for this part will be given for correctly setting up branch, etc., above, and for doing git commits/pushes mentioned throughout the assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e549e-214b-4858-930f-e2b7c9015580",
   "metadata": {},
   "source": [
    "``` bash\n",
    "git clone http://github.com/KlutzyFella/CMSE202-f25-turnin/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e93e6e-2297-490f-b1c8-a87bbd9d4814",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s25-turnin`\" repository inside the `hw-04` directory that you just created.\n",
    "\n",
    "Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the problems for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2cd6e-5eac-4817-afad-c1d8ab86214b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Deal with unfamiliar data (35 points)\n",
    "\n",
    "## Warm up with perceptron for binary classification\n",
    "## 2.1 Load up the dataset\n",
    "\n",
    "This data is obtained from Kaggle/diabetes. It contains multiple measured values and a label for whether the patient is diagnosed as diabetic. \n",
    "\n",
    "* Use commands to dowdload the dataset from `https://raw.githubusercontent.com/huichiayu/cmse202-s25-supllemental_data/refs/heads/main/HW04/diabetes_prediction_dataset.csv`\n",
    "* Use Pandas to load in the data and briefly examine it.\n",
    "* Succeed data load-up gets **2 pt**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "513bc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8dde6c3-799e-480b-ac67-a8e0d2716b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your code here\n",
    "diabetes_data = pd.read_csv(\"diabetes_prediction_dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac61eaf-8d5a-4889-8c9a-624aeefc511d",
   "metadata": {},
   "source": [
    "How many patients are in this dataset? What are features of the patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96197e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 100000\n",
      "Features of the patients: ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']\n"
     ]
    }
   ],
   "source": [
    "# Number of patients\n",
    "num_patients = diabetes_data.shape[0]\n",
    "print(f\"Number of patients: {num_patients}\")\n",
    "\n",
    "# Features of the patients\n",
    "features = diabetes_data.columns.tolist()\n",
    "print(f\"Features of the patients: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc156a61-260e-401d-a92d-d80a0016be0b",
   "metadata": {},
   "source": [
    "```\n",
    "There are a 100000 patients and the features are 'gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0e656-57ad-4757-b1c5-fa51c9aef9f9",
   "metadata": {},
   "source": [
    "### Use your perceptron class built in Day18 and Day19 assignments to classify whether patients are diabetic.\n",
    "\n",
    "* You should see that there are some features that are non-numerics.\n",
    "* The first one is `gender`. Find the types of classes and convert them to numerics in your dataframe.\n",
    "* The second one is `smoking_history`, convert those string labels to numerics.\n",
    "* Note that since perceptron is a binary classifier, which only determines which side of the dividing line the data points reside, we should also convert the labels to `+1` and `-1`.\n",
    "* Completing data conversion gets **5 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16bb0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  smoking_history  diabetes\n",
      "0       0                0        -1\n",
      "1       0                3        -1\n",
      "2       1                0        -1\n",
      "3       0                2        -1\n",
      "4       1                2        -1\n",
      "5       0                0        -1\n",
      "6       0                0         1\n",
      "7       0                3        -1\n",
      "8       1                0        -1\n",
      "9       0                0        -1\n"
     ]
    }
   ],
   "source": [
    "diabetes_data['gender'] = diabetes_data['gender'].map({\n",
    "    'Female': 0,\n",
    "    'Male': 1,\n",
    "    'Other': 2\n",
    "})\n",
    "\n",
    "diabetes_data['smoking_history'] = diabetes_data['smoking_history'].map({\n",
    "    'never': 0,\n",
    "    'former': 1,\n",
    "    'current': 2,\n",
    "    'No Info': 3,\n",
    "    'not current': 4,\n",
    "    'ever': 5\n",
    "})\n",
    "\n",
    "diabetes_data['diabetes'] = diabetes_data['diabetes'].map({\n",
    "    0: -1,\n",
    "    1: 1\n",
    "})\n",
    "\n",
    "print(diabetes_data[['gender', 'smoking_history', 'diabetes']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2245b-3a9e-4b17-a5e3-b2d8365034db",
   "metadata": {},
   "source": [
    "### Now all feature varilables are numerics.\n",
    "\n",
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Binary perceptron classifier\n",
    "\n",
    "Copy your perceptron class to the cell below. \n",
    "\n",
    "* DO NOT use the one from statsmodel. We want to test the perceptron you built.\n",
    "* Note that your predict method should output `+1` or `-1` for positive or negative values, respectively.\n",
    "* A functional perceptron classifier gets **4 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22f7672c-5fc3-4c4f-8d06-ec88508c81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your perceptron class to his cell\n",
    "# put your code here\n",
    "class PerceptronF():\n",
    "\n",
    "    def __init__(self, labeled_data, iters, learning_rate):\n",
    "        # Initialize attributes: data, weights, iterations, learning rate\n",
    "        self.data = np.array(labeled_data)\n",
    "        self.weights = np.ones(self.data.shape[1])\n",
    "        self.iters = iters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, feature_set):\n",
    "        # Add bias term to the feature set\n",
    "        feature_set_with_bias = np.insert(feature_set, 0, 1)\n",
    "        # Compute the dot product and apply the activation function\n",
    "        result = np.dot(self.weights, feature_set_with_bias)\n",
    "        return 1 if result > 0 else -1\n",
    "\n",
    "    def fit(self):\n",
    "        for _ in range(self.iters):\n",
    "            for row in self.data:\n",
    "                # Extract features and label\n",
    "                features = row[:-1]\n",
    "                label = row[-1]\n",
    "                # Predict the label\n",
    "                prediction = self.predict(features)\n",
    "                # Update weights if prediction is incorrect\n",
    "                if prediction != label:\n",
    "                    update = self.learning_rate * (label - prediction)\n",
    "                    # Update weights including bias\n",
    "                    self.weights[1:] += update * features\n",
    "                    self.weights[0] += update  # Update bias weight\n",
    "\n",
    "    def errors(self):\n",
    "        error_count = 0\n",
    "        for row in self.data:\n",
    "            # Extract features and label\n",
    "            features = row[:-1]\n",
    "            label = row[-1]\n",
    "            # Predict the label\n",
    "            prediction = self.predict(features)\n",
    "            # Count errors\n",
    "            if prediction != label:\n",
    "                error_count += 1\n",
    "        print(f\"Number of errors: {error_count}\")\n",
    "        print(f\"Current weights: {self.weights[1:]}\")\n",
    "        print(f\"Bias weight: {self.weights[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cf279-13af-4402-94c4-2c418d3d97a5",
   "metadata": {},
   "source": [
    "* Split data to 70-30 train-test sets **1 pt**.\n",
    "* Train your perceptron.\n",
    "* Show the accuracy of your pereptron **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7986537a-e054-4286-91a4-9ba639e3c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and labels after conversion\n",
    "feature_columns = ['gender', 'age', 'hypertension', 'heart_disease',\n",
    "                   'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "X = diabetes_data[feature_columns].values\n",
    "y = diabetes_data['diabetes'].values\n",
    "\n",
    "# Scale features (because your perceptron needs it)\n",
    "X_min = X.min(axis=0)\n",
    "X_max = X.max(axis=0)\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Prepare training data\n",
    "train_data_for_perceptron = np.hstack((X_train, y_train.reshape(-1, 1)))\n",
    "\n",
    "# Train perceptron\n",
    "perceptron = PerceptronF(labeled_data=train_data_for_perceptron, iters=100, learning_rate=0.1)\n",
    "perceptron.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22521abe-9552-41ec-8512-6995a7245ed7",
   "metadata": {},
   "source": [
    "* Use test set to evaulate the accuracy of your perceptron. What is your accuracy? (**2 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f6dd4c5-7bc1-4e9b-83e4-0417543b52d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Test Accuracy: 0.9354\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "\n",
    "# Predict and calculate test accuracy\n",
    "correct_predictions = 0\n",
    "for features, true_label in zip(X_test, y_test):\n",
    "    prediction = perceptron.predict(features)\n",
    "    if prediction == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "print(f\"Perceptron Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59cd13-1358-48ad-a11c-2371277e0b55",
   "metadata": {},
   "source": [
    "* There may be some ways to increase the accruacy, such as increasing the number of train iterations or adjust learning rate. Give a try to train a perceptron you can best get. Record the values of parameters and the optimal accuracy. (**3 pt**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3498a824-d111-451e-9119-6f85964bca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters=100, learning_rate=0.01, accuracy=0.9473\n",
      "iters=100, learning_rate=0.05, accuracy=0.9447\n",
      "iters=100, learning_rate=0.1, accuracy=0.9354\n",
      "iters=100, learning_rate=0.2, accuracy=0.9029\n",
      "iters=200, learning_rate=0.01, accuracy=0.9395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train perceptron with different parameters\u001b[39;00m\n\u001b[0;32m     12\u001b[0m perceptron \u001b[38;5;241m=\u001b[39m PerceptronF(labeled_data\u001b[38;5;241m=\u001b[39mtrain_data_for_perceptron, iters\u001b[38;5;241m=\u001b[39miters, learning_rate\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mperceptron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[0;32m     16\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn [57], line 26\u001b[0m, in \u001b[0;36mPerceptronF.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Predict the label\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Update weights if prediction is incorrect\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m!=\u001b[39m label:\n",
      "Cell \u001b[1;32mIn [57], line 16\u001b[0m, in \u001b[0;36mPerceptronF.predict\u001b[1;34m(self, feature_set)\u001b[0m\n\u001b[0;32m     14\u001b[0m feature_set_with_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(feature_set, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute the dot product and apply the activation function\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_set_with_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "best_accuracy = 0\n",
    "best_iters = None\n",
    "best_lr = None\n",
    "\n",
    "for iters in [100, 200, 300, 500]:\n",
    "    for lr in [0.01, 0.05, 0.1, 0.2]:\n",
    "        # Prepare training data\n",
    "        train_data_for_perceptron = np.hstack((X_train, y_train.reshape(-1, 1)))\n",
    "\n",
    "        # Train perceptron with different parameters\n",
    "        perceptron = PerceptronF(labeled_data=train_data_for_perceptron, iters=iters, learning_rate=lr)\n",
    "        perceptron.fit()\n",
    "\n",
    "        # Evaluate on test set\n",
    "        correct_predictions = 0\n",
    "        for features, true_label in zip(X_test, y_test):\n",
    "            prediction = perceptron.predict(features)\n",
    "            if prediction == true_label:\n",
    "                correct_predictions += 1\n",
    "        accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "        # If this model is the best so far, record it\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_iters = iters\n",
    "            best_lr = lr\n",
    "\n",
    "        print(f\"iters={iters}, learning_rate={lr}, accuracy={accuracy:.4f}\")\n",
    "\n",
    "# Final best result\n",
    "print(\"\\nBest Accuracy:\")\n",
    "print(f\"Iterations: {best_iters}\")\n",
    "print(f\"Learning Rate: {best_lr}\")\n",
    "print(f\"Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6d5b3",
   "metadata": {},
   "source": [
    "```\n",
    "As we can see, it was taking too long to run through all iterations so I might decide to run this later but for now the pattern suggests that \n",
    "iter = 100, and learning_rate = 0.01 gave the best accuracy of 0.9473\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41900123-9fa6-4dbb-81de-0b90edc3d9e5",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Next we shall test perceptron's capability of multiple-label classification.\n",
    "\n",
    "* Dowdload the dataset from `https://raw.githubusercontent.com/huichiayu/cmse202-s25-supllemental_data/refs/heads/main/HW04/Telecust1.csv`.\n",
    "* This is a customer category dataset (Kraggle/Customer Classification). Each cusmtoer has several feature variables.\n",
    "* There are five categories of customers, which are non-numerics. Thus, let's convert those string labels to numerics.\n",
    "* Successful data load-up gets **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f57127a-9d83-4408-a18d-8adfb800eb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  tenure  age  income  marital  address  ed  employ  retire  gender  \\\n",
       "0       2      13   44      64        1        9   4       5       0       0   \n",
       "1       3      11   33     136        1        7   5       5       0       0   \n",
       "2       3      68   52     116        1       24   1      29       0       1   \n",
       "3       2      33   33      33        0       12   2       0       0       1   \n",
       "4       2      23   30      30        1        9   1       2       0       0   \n",
       "\n",
       "   reside  custcat  \n",
       "0       2        0  \n",
       "1       6        3  \n",
       "2       2        2  \n",
       "3       1        0  \n",
       "4       4        2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and load the dataset. Convert non-numerical labels to numerics.\n",
    "# put your code here\n",
    "\n",
    "# put your code here\n",
    "telecust_data = pd.read_csv(\"telecust.csv\")\n",
    "\n",
    "# Map customer categories to numbers\n",
    "custcat_mapping = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3\n",
    "}\n",
    "\n",
    "telecust_data['custcat'] = telecust_data['custcat'].map(custcat_mapping)\n",
    "\n",
    "# Check first few rows after mapping\n",
    "telecust_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcab03b-57fb-4268-81dc-e72281bfceb1",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.4 Multi-label perceptron classification\n",
    "\n",
    "* As we know, perceptron is a binary classifier. For multiple-label classification, we can use One-vs-Rest (OvR) Strategy.\n",
    "* In this case, let's train five individual perceptrons. \n",
    "* For each classifier, it treats the current class as \"positive\" and all others as \"negative.\"\n",
    "* When classifying a new sample, each classifier gives a \"score,\" and the class with the highest score is chosen.\n",
    "\n",
    "Copy your perceptron to the code cell below. We need to add a score method, which outputs dot of weights and features, as opposed to the previous binary predict method. The score method should output a signed floating score value, not `+1` or `-1`. This can be done by removing the binary segmenting, i.e., directly outputing the dot value.\n",
    "\n",
    "* Functioning score() method gets **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7996b89-84fb-4272-9c30-c5293a97455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your modified perceptron class here\n",
    "\n",
    "class PerceptronF():\n",
    "\n",
    "    def __init__(self, labeled_data, iters, learning_rate):\n",
    "        # Initialize attributes: data, weights, iterations, learning rate\n",
    "        self.data = np.array(labeled_data)\n",
    "        self.weights = np.ones(self.data.shape[1])\n",
    "        self.iters = iters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, feature_set):\n",
    "        # Add bias term to the feature set\n",
    "        feature_set_with_bias = np.insert(feature_set, 0, 1)\n",
    "        # Compute the dot product and apply the activation function\n",
    "        result = np.dot(self.weights, feature_set_with_bias)\n",
    "        return 1 if result > 0 else -1\n",
    "\n",
    "    def fit(self):\n",
    "        for _ in range(self.iters):\n",
    "            for row in self.data:\n",
    "                # Extract features and label\n",
    "                features = row[:-1]\n",
    "                label = row[-1]\n",
    "                # Predict the label\n",
    "                prediction = self.predict(features)\n",
    "                # Update weights if prediction is incorrect\n",
    "                if prediction != label:\n",
    "                    update = self.learning_rate * (label - prediction)\n",
    "                    # Update weights including bias\n",
    "                    self.weights[1:] += update * features\n",
    "                    self.weights[0] += update  # Update bias weight\n",
    "\n",
    "    def errors(self):\n",
    "        error_count = 0\n",
    "        for row in self.data:\n",
    "            # Extract features and label\n",
    "            features = row[:-1]\n",
    "            label = row[-1]\n",
    "            # Predict the label\n",
    "            prediction = self.predict(features)\n",
    "            # Count errors\n",
    "            if prediction != label:\n",
    "                error_count += 1\n",
    "        print(f\"Number of errors: {error_count}\")\n",
    "        print(f\"Current weights: {self.weights[1:]}\")\n",
    "        print(f\"Bias weight: {self.weights[0]}\")\n",
    "\n",
    "    def score(self, feature_set):\n",
    "        # Add bias term to the feature set\n",
    "        feature_set_with_bias = np.insert(feature_set, 0, 1)\n",
    "        # Compute and return the dot product (raw score)\n",
    "        return np.dot(self.weights, feature_set_with_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e1e42-e58d-49c5-a7ce-bdbb9f8e3d50",
   "metadata": {},
   "source": [
    "\n",
    "* Now let's do a train-test split of the data with a test_size = 0.3.\n",
    "* Since we are training 5 perceptrons, we should have have 5 class label sets. For instance, in the label set for category A, the label value will be `+1` if it's type A and otherwise `-1`.\n",
    "* Setting label sets gets **4 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e59a1422-8984-49b8-889e-e34c6172e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "X = telecust_data.drop('custcat', axis=1).values\n",
    "y = telecust_data['custcat'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train_sets = []\n",
    "for class_label in range(5):\n",
    "    binary_labels = np.where(y_train == class_label, 1, -1)\n",
    "    y_train_sets.append(binary_labels)\n",
    "\n",
    "y_test_sets = []\n",
    "for class_label in range(5):\n",
    "    binary_labels = np.where(y_test == class_label, 1, -1)\n",
    "    y_test_sets.append(binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245187a-3ed6-4cc4-a844-7fd0493707c9",
   "metadata": {},
   "source": [
    "* Use training set and the 5 training label sets to train your 5 perceptrons. Report the accuracy of those five training.\n",
    "* Efficiently train the five perceptrons using nest loop gets **5 pt**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be107995-7f86-48d8-b24a-d3f3ed8b9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 0 (class 0) training accuracy: 0.7586\n",
      "Perceptron 1 (class 1) training accuracy: 0.3314\n",
      "Perceptron 2 (class 2) training accuracy: 0.7171\n",
      "Perceptron 3 (class 3) training accuracy: 0.7100\n",
      "Perceptron 4 (class 4) training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "\n",
    "# store the 5 perceptrons\n",
    "perceptrons = []  \n",
    "# store the training accuracies\n",
    "train_accuracies = []  \n",
    "\n",
    "for i in range(5):  \n",
    "    # Prepare data for this perceptron\n",
    "    labeled_data = np.hstack((X_train, y_train_sets[i].reshape(-1, 1)))\n",
    "    \n",
    "    # Initialize and train perceptron\n",
    "    perceptron = PerceptronF(labeled_data=labeled_data, iters=100, learning_rate=0.1)\n",
    "    perceptron.fit()\n",
    "    perceptrons.append(perceptron)\n",
    "    \n",
    "    # Evaluate on training set\n",
    "    correct_predictions = 0\n",
    "    for features, true_label in zip(X_train, y_train_sets[i]):\n",
    "        prediction = perceptron.predict(features)\n",
    "        if prediction == true_label:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(y_train_sets[i])\n",
    "    train_accuracies.append(accuracy)\n",
    "    \n",
    "    print(f\"Perceptron {i} (class {i}) training accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550cc5-fbc2-42a2-8713-881783f2c7f9",
   "metadata": {},
   "source": [
    "* Use the test vector to examine the accuracy.\n",
    "* For each feature set, there should be 5 output scores, each from a perceptron. The predicted label should be the label that corresponds to the highest score.\n",
    "* Report your accuracy. (**3 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e549131-9459-437b-b627-bc99e0fa93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Perceptron Test Accuracy: 0.2667\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for features in X_test:\n",
    "    scores = []\n",
    "    for perceptron in perceptrons:\n",
    "        score = perceptron.score(features)\n",
    "        scores.append(score)\n",
    "    predicted_label = np.argmax(scores)\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "# Calculate test accuracy\n",
    "correct_predictions = sum(pred == true for pred, true in zip(y_pred, y_test))\n",
    "test_accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "print(f\"Multiclass Perceptron Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31084b-0308-4fd0-b912-bf42f13ee674",
   "metadata": {},
   "source": [
    "How good is your multiple-label perceptron classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598a593-aac1-48b7-b634-f6c046f256f3",
   "metadata": {},
   "source": [
    "```\n",
    "The accuracy I got for my multiclass perceptron was 26.67%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b1bce-e2ce-4bd4-ae8e-9aca6d76a163",
   "metadata": {},
   "source": [
    "\n",
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "## Part 3 SVM classifiers (19 points)\n",
    "\n",
    "### 3.1 SVM \n",
    "\n",
    "Let's re-use the customer category data. There are five caterogies with multiple feature variables.\n",
    "\n",
    "* Use sklearn library to build a SVM classifier. Since we do not know what the best parametes are, perform a GridSearch for best parameters.\n",
    "* NOTE: Because the dataset contains a large number of points, it's expected to have a long computer running time for GridSearch. Thus, let's use only the first 200 data points for GridSearch. You can start the grid search parameter like the image below. However, **NOTE** that if the kernal used cannot find a hyperplane to classify data points, the GridSearch function will stall. You need to manually remove that kernal from the parameter set and re-run GridSearch.\n",
    "  \n",
    "<img src=\"https://i.ibb.co/JWrp6c4q/Grid-Search-Param.png\" width=\"650\">\n",
    "\n",
    "\n",
    "* As in the previous section, make a 70-30 train-test split and train your SVM classifier.\n",
    "* Complete GridSearch to extract best parameters gets **5 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83c8b3-cc1b-4fa6-a2f7-f627339586d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af730354-6eee-40f2-9a19-a20c8be0f3db",
   "metadata": {},
   "source": [
    "* Examine the accuracy of this SVC and report the accuracy. Draw a confusion matrix. **2 pt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b7f0b-97b1-474f-b0b0-09574d54a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf396ba-1d88-4d14-8771-210dc41fcbcf",
   "metadata": {},
   "source": [
    "Does SVM classifier work much better than your percetron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81488c96-0326-408f-aed9-d956ee068d65",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5af1a-7950-4356-bc42-29c41b31c03d",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "### 3.2 PCA \n",
    "\n",
    "Although we only have 11 feature variables in the dataset, let's examine how much principal component analysis (PCA) can accelerate the classification. We will increase the PCA components from 1 to 11. For each case, we will perform a GridSearch and use test set to examine the accuracy. \n",
    "\n",
    "* Write a code to loop over n_components = 1 through 11. **4 pt**\n",
    "* Record the accuracy of each case and plot the profile of accuracy versus n_components. In the mean time, record the computer run times and plot the profile of time versus n_components. **2 pt**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7c31b-cc0f-4ce7-9156-cc1207b26186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f02dd4-9ad8-416f-8324-cede07489a0a",
   "metadata": {},
   "source": [
    "Please answer the following questions. \n",
    "* How is the overall accuracy of this SVM classifier?  **1 pt**\n",
    "* If the performance is not good, what do you think the cause is? **2 pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5f56b-173e-4013-9ccb-cd717aaf2524",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ccaefe-5020-42f3-8d1b-2359bcdb535d",
   "metadata": {},
   "source": [
    "* Describe the curves of time vs n_components and accuracy vs n_components. **1 pt**\n",
    "* Explain why the curves behave as they are in the figures **2 pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43066ffe-1bdb-4c50-b4dd-ecec5287fc64",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10fcb2-8d8b-4e2f-a9fe-5b998e646114",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your FINAL changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Assignment wrap-up\n",
    "\n",
    "\n",
    "Please fill out the form that appears when you run the code below.  **You must completely fill this out in order to receive credit for the assignment!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa2c83-4226-47d8-ad62-0a15001b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://forms.office.com/r/mB0YjLYvAA\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f1ca9-1cce-4437-a38d-163b31945d70",
   "metadata": {},
   "source": [
    "## Congratulations, you're done!\n",
    "\n",
    "&#169; Copyright 2025,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ef267-8dfb-4e1c-86b7-d4c4d42d6bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
